
# MyMeet.AI Web Scraper
Этот проект представляет собой веб-скраппер для сайта MyMeet.AI, разработанный как тестовое задание для позиции JS Fullstack разработчика. Скраппер собирает текстовый контент и изображения с главной страницы сайта и сохраняет их в отдельные директории.

## Функциональность
- Сбор текстового контента с главной страницы
- Загрузка всех изображений
- Сохранение контента в организованную структуру директорий
- Подробное логирование процесса
- Обработка ошибок
- Настраиваемая конфигурация через переменные окружения

## Технологии
- Node.js
- Puppeteer
- Jest
- fs-extra

## Структура проекта
project/
├── src/
│ ├── config.js # Конфигурация приложения
│ ├── index.js # Точка входа
│ ├── services/
│ │ └── scraper/ # Сервис для скраппинга
│ │ ├── scraper.js
│ │ └── scraper.test.js
│ └── utils/
│ ├── file-manager.js # Утилита для работы с файлами
│ └── logger # Утилита для красивого вывода информации в консоль
├── babel.config.js # Конфигурация Babel
├── jest.config.js # Конфигурация Jest
├── jest.setup.js # Настройки тестового окружения
└── package.json

## Установка
1. Клонируйте репозиторий:
```bash
git  clone git@github.com:CyberPanCake3000/MeetAI-Test.git
cd MeetAI-Test
```
2. Установите зависимости:
```
npm install
```
3. Переименуйте файл .env.example в .env и внесите свои корректные данные:
```
TARGET_WEBSITE_URL='https://example.com/'
TARGET_TEXT_DIR='text'
TARGET_PICTURE_DIR='img'
MAIN_RESULT_DIR='result'
```

## Использование
Запуск скраппера:
```
npm start
```
Запуск в режиме разработки (с nodemon):
```
npm run dev
```
## Тестирование
Запуск всех тестов:
```
npm test
```
Запуск тестов в режиме watch:
```
npm run test:watch
```
## Структура результатов
После выполнения скраппера, результаты будут сохранены в следующей структуре:
```
result/
├── text/
│ └── content.txt # Весь текстовый контент
└── images/
├── image_0_*.png # Изображения с сайта
├── image_1_*.png
└── ...
```
Возможные улучшения

- [ ] Добавить поддержку многостраничного скраппинга
- [ ] Реализовать параллельную загрузку изображений
- [ ] Добавить CLI интерфейс для управления параметрами скраппинга
- [ ] Реализовать систему очередей для больших объемов данных